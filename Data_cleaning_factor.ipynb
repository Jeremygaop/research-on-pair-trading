{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmZqVIQYDyZ6",
        "outputId": "6f1cf987-03f2-493d-8af1-14920b0bec97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "import warnings\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "R3LnzYh2mbxk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define path to read the data\n",
        "trading_pairs = {'JBF':'3443','QWF':'2388','HCF':'2498','DBF':'2610','EHF':'1319','IPF':'3035','IIF':'3006','QXF':'2615','PEF':'5425','NAF':'3105'}\n",
        "stock_path = \"/content/drive/MyDrive/Colab Notebooks/Independent project_2023 Summer/stocks\"\n",
        "stock_files = os.listdir(stock_path)\n",
        "futures_path = \"/content/drive/MyDrive/Colab Notebooks/Independent project_2023 Summer/futuresOB\"\n",
        "futures_files = os.listdir(futures_path)\n",
        "futures_trade_path = \"/content/drive/MyDrive/Colab Notebooks/Independent project_2023 Summer/futuresTrades\"\n",
        "futures_trade_files = os.listdir(futures_trade_path)\n",
        "stock_files.remove('.DS_Store')\n",
        "futures_files.remove('.DS_Store')\n",
        "#futures_trade_files.remove('.DS_Store')"
      ],
      "metadata": {
        "id": "NK07SPDpD7fm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "futures_trade_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FujkN1UeGP42",
        "outputId": "0bdb5831-1175-4ba8-fddf-dffdb9a1af64"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['HCF', 'IPF', 'IIF', 'QXF', 'QWF', 'EHF', 'NAF', 'JBF', 'PEF', 'DBF']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "futures_files"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpvdVyQAeQrr",
        "outputId": "914579ad-c84d-4f85-968f-ad6722a899fe"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['JBF', 'PEF', 'QXF', 'IPF', 'EHF', 'IIF', 'NAF', 'QWF', 'DBF', 'HCF']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ln_ratio(x):\n",
        "    return np.log(x.max() / x.min())\n",
        "\n",
        "def count_nonzero(x):\n",
        "    return x.notna().sum()\n",
        "\n",
        "#Function to read stock data from csv file, stock name is element in stock_files\n",
        "def read_stock_data(stock_name):\n",
        "    #stock_data stores list of .gz files\n",
        "    stock_data = os.listdir(stock_path + '/' + stock_name)\n",
        "    stock_price_one_minute = pd.DataFrame()\n",
        "    for file in stock_data:\n",
        "      stock_tick = pd.read_csv(stock_path + '/' + stock_name + '/' + file, compression='gzip')\n",
        "\n",
        "      #Data cleaning, drop na data.\n",
        "      stock_tick= stock_tick.loc[stock_tick['SP1'] * stock_tick['BP1'] != 0]\n",
        "\n",
        "      #Convert date to datetime format\n",
        "      stock_tick['date'] = pd.to_datetime(stock_tick['date'], format=\"%Y-%m-%d\")\n",
        "\n",
        "      # set a timestamp every 1 min starting from 9:01, which represents trade happens in the minute just passed.\n",
        "      stock_tick['new_time'] =  stock_tick['time'] +(100000 - stock_tick['time'] % 100000)\n",
        "\n",
        "      # if minute is 60, adjust time accordingly.\n",
        "      stock_tick['new_time'] = stock_tick['new_time'] + (stock_tick['new_time'] % 10000000 == 6000000) * 4000000\n",
        "      stock_tick['time_stamp'] = pd.to_datetime(stock_tick.date.astype(str) + ' ' + stock_tick.new_time.astype(str), format=\"%Y-%m-%d %H%M%S%f\")\n",
        "\n",
        "      # get the column 'SP1','BP1' and calculate the mid quote\n",
        "      stock_tick['mid_quote'] = np.log(stock_tick[['SP1','BP1']].mean(axis=1))\n",
        "\n",
        "      result = stock_tick.groupby('time_stamp').agg({\n",
        "          'mid_quote': [ln_ratio,'mean'],\n",
        "          'volume': 'count',\n",
        "          'size' : count_nonzero,\n",
        "          'BV1': 'sum',\n",
        "          'BV2': 'sum',\n",
        "          'BV3': 'sum',\n",
        "          'BV4': 'sum',\n",
        "          'BV5': 'sum',\n",
        "          'SV1': 'sum',\n",
        "          'SV2': 'sum',\n",
        "          'SV3': 'sum',\n",
        "          'SV4': 'sum',\n",
        "          'SV5': 'sum'\n",
        "      })\n",
        "\n",
        "      result['bid_ask_ratio'] = (result['BV1'] + result['BV2'] + result['BV3'] + result['BV4']+ result['BV5']) / (result['SV1'] + result['SV2'] + result['SV3'] + result['SV4'] + result['SV5'])\n",
        "      result['bid1_ask1_ratio'] = (result['BV1']) / (result['SV1'])\n",
        "      result = result.droplevel(0, axis=1)\n",
        "      result = result.iloc[:, [0, 1, 2, 3, 14, 15]]\n",
        "      result.columns = ['max_min_ratio', 'mid_quote','trade_count', 'quote_count',  'bid_ask_ratio', 'bid1_ask1_ratio']\n",
        "\n",
        "      stock_price_one_minute = pd.concat([stock_price_one_minute, result], axis=0)\n",
        "    return(stock_price_one_minute)"
      ],
      "metadata": {
        "id": "-yRrCFZ-EQ34"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to read futures data from csv file, futures name is element in futures_files\n",
        "def read_futures_data(futures_name):\n",
        "    #stock_data stores list of .gz files\n",
        "    futures_data = os.listdir(futures_path + '/' + futures_name)\n",
        "    futures_price_one_minute = pd.DataFrame()\n",
        "    for file in futures_data:\n",
        "      futures_tick = pd.read_csv(futures_path + '/' + futures_name + '/' + file)\n",
        "\n",
        "      #Data cleaning, drop na data.\n",
        "      futures_tick = futures_tick.loc[futures_tick['askPrice1'] * futures_tick['bidPrice1'] != 0]\n",
        "\n",
        "      #Convert date to datetime format\n",
        "      futures_tick['date'] = pd.to_datetime(futures_tick['date'], format=\"%Y-%m-%d\")\n",
        "\n",
        "      # set a timestamp every 1 min starting from 9:01, which represents trade happens in the minute just passed.\n",
        "      futures_tick['new_time'] =  futures_tick['time'] +(100000 - futures_tick['time'] % 100000)\n",
        "\n",
        "      # if minute is 60, adjust time accordingly.\n",
        "      futures_tick['new_time'] = futures_tick['new_time'] + (futures_tick['new_time'] % 10000000 == 6000000) * 4000000\n",
        "      futures_tick['time_stamp'] = pd.to_datetime(futures_tick.date.astype(str) + ' ' + futures_tick.new_time.astype(str), format=\"%Y-%m-%d %H%M%S%f\")\n",
        "\n",
        "      # get the column 'SP1','BP1' and calculate the mid quote\n",
        "      futures_tick['mid_quote'] = np.log(futures_tick[['askPrice1','bidPrice1']].mean(axis=1))\n",
        "\n",
        "\n",
        "      result = futures_tick.groupby('time_stamp').agg({\n",
        "      'mid_quote': [ln_ratio,'mean'],\n",
        "      'time': 'count',\n",
        "      'bidSize1': 'sum',\n",
        "      'bidSize2': 'sum',\n",
        "      'bidSize3': 'sum',\n",
        "      'bidSize4': 'sum',\n",
        "      'bidSize5': 'sum',\n",
        "      'askSize1': 'sum',\n",
        "      'askSize2': 'sum',\n",
        "      'askSize3': 'sum',\n",
        "      'askSize4': 'sum',\n",
        "      'askSize5': 'sum'\n",
        "    })\n",
        "\n",
        "      result['bid_ask_ratio'] = (result['bidSize1'] + result['bidSize2'] + result['bidSize3'] + result['bidSize4']+ result['bidSize5']) / (result['askSize1'] + result['askSize2'] + result['askSize3'] + result['askSize4'] + result['askSize5'])\n",
        "      result['bid1_ask1_ratio'] = (result['bidSize1']) / (result['askSize1'])\n",
        "      result = result.droplevel(0, axis=1)\n",
        "      result = result.iloc[:, [0, 1, 2, 13, 14]]\n",
        "      result.columns = ['max_min_ratio', 'mid_quote', 'quote_count',  'bid_ask_ratio', 'bid1_ask1_ratio']\n",
        "\n",
        "      futures_price_one_minute = pd.concat([futures_price_one_minute, result], axis=0)\n",
        "\n",
        "    return(futures_price_one_minute)\n"
      ],
      "metadata": {
        "id": "4sqwtdFKHZmv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to read futures trade data from csv file, futures name is element in futures_files\n",
        "def read_trade_data(futures_name):\n",
        "    #stock_data stores list of .gz files\n",
        "    futures_data = os.listdir(futures_trade_path + '/' + futures_name)\n",
        "    futures_trade_one_minute = pd.DataFrame()\n",
        "    for file in futures_data:\n",
        "      futures_tick = pd.read_csv(futures_trade_path + '/' + futures_name + '/' + file)\n",
        "      #Data cleaning, drop na data.\n",
        "      futures_tick = futures_tick.loc[futures_tick['totalMatchValue'] != 0]\n",
        "\n",
        "      #Convert date to datetime format\n",
        "      futures_tick['date'] = pd.to_datetime(futures_tick['Date'], format=\"%Y-%m-%d\")\n",
        "\n",
        "      # set a timestamp every 1 min starting from 9:01, which represents trade happens in the minute just passed.\n",
        "      futures_tick['new_time'] =  futures_tick['Time'] +(100000 - futures_tick['Time'] % 100000)\n",
        "      futures_tick = futures_tick.sort_values(by = ['date', 'Time'], ascending=True)\n",
        "      # if minute is 60, adjust time accordingly.\n",
        "      futures_tick['new_time'] = futures_tick['new_time'] + (futures_tick['new_time'] % 10000000 == 6000000) * 4000000\n",
        "      futures_tick['time_stamp'] = pd.to_datetime(futures_tick.date.astype(str) + ' ' + futures_tick.new_time.astype(str), format=\"%Y-%m-%d %H%M%S%f\")\n",
        "      result = futures_tick.groupby('time_stamp').agg({\n",
        "            'totalMatchSize': 'count'\n",
        "          })\n",
        "      result.columns = ['trade_count']\n",
        "\n",
        "      futures_trade_one_minute = pd.concat([futures_trade_one_minute, result], axis=0)\n",
        "\n",
        "    return(futures_trade_one_minute)\n"
      ],
      "metadata": {
        "id": "xCNLDt1tvQLU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_spread(futures_name):\n",
        "    spread = (read_stock_data(trading_pairs[futures_name]) - read_futures_data(futures_name)).dropna()\n",
        "    spread = spread.reset_index()\n",
        "    spread['date'] = spread['time_stamp'].dt.date\n",
        "    spread['time'] = spread['time_stamp'].dt.time\n",
        "    spread = spread.set_index('time_stamp', drop = True)\n",
        "    return spread"
      ],
      "metadata": {
        "id": "FIL3WYhHmdq3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trading_pairs.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH8RzUzCP2nK",
        "outputId": "e0629f7a-7f1b-4936-d6ad-634f7041d2fe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['JBF', 'QWF', 'HCF', 'DBF', 'EHF', 'IPF', 'IIF', 'QXF', 'PEF', 'NAF'])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trading_pairs['JBF']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ek7Fm3a2P5vk",
        "outputId": "52184366-a145-4bed-ff8a-6a520140dd9c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3443'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for future_name in tqdm(trading_pairs.keys()):\n",
        "  stock_factor = read_stock_data(trading_pairs[future_name])\n",
        "  futures_ = read_futures_data(future_name)\n",
        "  futures_trade = read_trade_data(future_name).sort_index()\n",
        "  stock_factor.to_csv('/content/drive/MyDrive/Colab Notebooks/Independent project_2023 Summer/FactorData/stocks/' + trading_pairs[future_name] + '.csv')\n",
        "  futures_factor = pd.merge(futures_,futures_trade,on = 'time_stamp',how = 'left').fillna(0)\n",
        "  futures_factor = futures_factor.loc[futures_trade.index[0]: ,]\n",
        "  futures_factor.to_csv('/content/drive/MyDrive/Colab Notebooks/Independent project_2023 Summer/FactorData/futures/' + future_name + '.csv')\n",
        "  spread = (stock_factor['mid_quote'] - futures_factor['mid_quote']).dropna()\n",
        "  spread.to_csv('/content/drive/MyDrive/Colab Notebooks/Independent project_2023 Summer/NewSpread/' + future_name + '.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keOOF9Y9vu0b",
        "outputId": "51d5be67-9270-46ab-b5ce-a73582f2d1e7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [42:27<00:00, 254.79s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "guryybO94-HE"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spread = (stock_factor['mid_quote'] - futures_factor['mid_quote']).dropna()\n",
        "spread.to_csv('/content/drive/MyDrive/Colab Notebooks/Independent project_2023 Summer/NewSpread/' + 'JBF.csv')"
      ],
      "metadata": {
        "id": "-Zo0yGTatnpU"
      },
      "execution_count": 120,
      "outputs": []
    }
  ]
}